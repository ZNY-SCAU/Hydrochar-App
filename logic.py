import joblib
import pandas as pd
import numpy as np
import random
import traceback
import warnings
import os

# è¿‡æ»¤è­¦å‘Š
warnings.filterwarnings('ignore')

class ModelBackend:
    def __init__(self, model_path="GUI_Model_Package.pkl"):
        self.model_path = model_path
        self.model = None
        self.scaler = None
        self.ui_numeric_cols = []
        self.ui_cat_cols = []
        self.stats = {}       
        self.cat_options = {} 
        self.model_features = [] 

    def load_model(self):
        """åŠ è½½æ¨¡å‹åŒ…ï¼Œä¿æŒåŸæœ‰é€»è¾‘ä¸å˜"""
        try:
            if not os.path.exists(self.model_path):
                return False, "Model file not found: GUI_Model_Package.pkl"

            package = joblib.load(self.model_path)
            self.model = package['model']
            self.scaler = package['scaler']
            
            # ä¼˜å…ˆè¯»å–æ¨¡å‹çœŸå®çš„ç‰¹å¾å
            if hasattr(self.model, "feature_names_in_"):
                self.model_features = list(self.model.feature_names_in_)
            else:
                self.model_features = package['model_features']
            
            self.ui_numeric_cols = package.get('ui_numeric_cols', [])
            self.ui_cat_cols = package.get('ui_cat_cols', [])
            self.stats = package.get('ui_numeric_stats', {})
            self.cat_options = package.get('ui_cat_options', {})
            
            return True, "Loaded successfully"
        except Exception as e:
            return False, f"Load failed: {str(e)}"

    def _build_input_df(self, params_dict):
        """æ„å»ºè¾“å…¥DataFrameï¼Œç¡®ä¿ç‰¹å¾é¡ºåºä¸è®­ç»ƒæ—¶ä¸€è‡´"""
        df = pd.DataFrame(0.0, index=[0], columns=self.model_features)
        
        # å¡«å……æ•°å€¼ç‰¹å¾
        for col in self.ui_numeric_cols:
            val = params_dict.get(col)
            if val is not None and col in self.model_features:
                df[col] = float(val)
        
        # å¡«å……åˆ†ç±»ç‰¹å¾ï¼ˆOne-Hoté€»è¾‘ï¼‰
        for cat_col in self.ui_cat_cols:
            selected_val = params_dict.get(cat_col)
            if selected_val:
                options = self.cat_options.get(cat_col, [])
                is_baseline = (options and selected_val == options[0]) or ("(åŸºå‡†)" in selected_val) or ("0" == selected_val)
                if not is_baseline and selected_val in self.model_features:
                    df[selected_val] = 1.0

        # æ ‡å‡†åŒ–å¤„ç†
        if self.scaler:
            try:
                if hasattr(self.scaler, "feature_names_in_"):
                    scaler_cols = list(self.scaler.feature_names_in_)
                    # åªå¯¹å­˜åœ¨çš„åˆ—è¿›è¡Œæ ‡å‡†åŒ–
                    if all(c in df.columns for c in scaler_cols):
                        sub_df = df[scaler_cols]
                        df[scaler_cols] = self.scaler.transform(sub_df)
            except: pass
        return df

    # ================= ğŸ§¬ è‡ªå®šä¹‰é—ä¼ ç®—æ³• (Genetic Algorithm) =================
    def _run_genetic_algorithm(self, objective_func, bounds, pop_size=50, generations=40, mutation_rate=0.1):
        """
        è½»é‡çº§å®æ•°ç¼–ç é—ä¼ ç®—æ³•ï¼Œä¸“ä¸º Streamlit ä¼˜åŒ–
        :param objective_func: ç›®æ ‡å‡½æ•°ï¼ˆæŸå¤±å‡½æ•°ï¼‰
        :param bounds: å˜é‡èŒƒå›´ [(min, max), ...]
        :param pop_size: ç§ç¾¤å¤§å° (é»˜è®¤50)
        :param generations: è¿­ä»£ä»£æ•° (é»˜è®¤40)
        :param mutation_rate: å˜å¼‚ç‡
        """
        # 1. åˆå§‹åŒ–
        n_vars = len(bounds)
        lb = np.array([b[0] for b in bounds])
        ub = np.array([b[1] for b in bounds])
        
        # éšæœºç”Ÿæˆåˆå§‹ç§ç¾¤ [pop_size, n_vars]
        population = lb + (ub - lb) * np.random.rand(pop_size, n_vars)
        
        best_solution = None
        best_fitness = float('inf')

        # å¼€å§‹è¿›åŒ–è¿­ä»£
        for gen in range(generations):
            # 2. è¯„ä¼°é€‚åº”åº¦ (Fitness Evaluation)
            # æ³¨æ„ï¼šè¿™é‡Œçš„ objective_func è¶Šå°è¶Šå¥½ï¼ˆæŸå¤±å‡½æ•°ï¼‰
            fitness = np.array([objective_func(ind) for ind in population])
            
            # è®°å½•æœ¬ä»£æœ€ä¼˜
            min_idx = np.argmin(fitness)
            if fitness[min_idx] < best_fitness:
                best_fitness = fitness[min_idx]
                best_solution = population[min_idx].copy()
            
            # 3. é€‰æ‹© (Selection) - é”¦æ ‡èµ›é€‰æ‹©æ³•
            # éšæœºé€‰ä¸¤ç»„ï¼Œä¸¤ä¸¤PKï¼Œä¿ç•™èƒœè€…
            idx1 = np.random.randint(0, pop_size, pop_size)
            idx2 = np.random.randint(0, pop_size, pop_size)
            mask = fitness[idx1] < fitness[idx2] # è°æŸå¤±å°è°èµ¢
            winners_idx = np.where(mask, idx1, idx2)
            parents = population[winners_idx]

            # 4. äº¤å‰ (Crossover) - ç®€å•ç®—æœ¯äº¤å‰
            offspring = parents.copy()
            # å°†çˆ¶ä»£æ‰“ä¹±
            np.random.shuffle(offspring)
            
            # åˆ’åˆ†ä¸ºä¸¤åŠè¿›è¡Œé…å¯¹
            cut_point = pop_size // 2
            p1 = offspring[:cut_point]
            p2 = offspring[cut_point : 2*cut_point]
            
            # éšæœºç”Ÿæˆäº¤å‰æ¯”ä¾‹ alpha
            alpha = np.random.rand(cut_point, n_vars)
            
            # ç”Ÿæˆå­ä»£
            c1 = alpha * p1 + (1 - alpha) * p2
            c2 = (1 - alpha) * p1 + alpha * p2
            
            # æ›´æ–°å­ä»£ç§ç¾¤
            offspring[:cut_point] = c1
            offspring[cut_point : 2*cut_point] = c2

            # 5. å˜å¼‚ (Mutation) - åŠ¨æ€é«˜æ–¯å˜å¼‚
            # éšæœºé€‰æ‹©ä¸ªä½“è¿›è¡Œå˜å¼‚
            mutation_mask = np.random.rand(pop_size, n_vars) < mutation_rate
            
            # å˜å¼‚å¼ºåº¦ï¼šèŒƒå›´çš„ 10%
            sigma = 0.1 * (ub - lb)
            noise = np.random.normal(0, 1, (pop_size, n_vars)) * sigma
            
            offspring = offspring + mutation_mask * noise
            
            # 6. è¾¹ç•Œå¤„ç† (Clip) - ç¡®ä¿ä¸è¶…å‡ºç‰©ç†é™åˆ¶
            offspring = np.clip(offspring, lb, ub)
            
            # 7. ç²¾è‹±ç­–ç•¥ (Elitism) - å¼ºåˆ¶ä¿ç•™å†å²æœ€ä¼˜
            # å°†æœ¬ä»£æœ€å¥½çš„ä¸€å®šæ”¾å›å»ï¼Œæ›¿æ¢æ‰å­ä»£ä¸­éšæœºä¸€ä¸ª
            offspring[0] = best_solution
            
            population = offspring

        return best_solution

    def run_task(self, inputs, targets):
        """æ‰§è¡Œé¢„æµ‹æˆ–åæ¨ä»»åŠ¡"""
        try:
            # 1. ç‰©ç†ç¡¬é™ä½ (ä¸è®­ç»ƒä»£ç ä¿æŒä¸€è‡´)
            BASE_HARD_LIMITS = {
                'activation-SLR(g/L)': {'min': 0.0, 'max': 100.0},
                'activator-concentration(mol/L)': {'min': 0.0, 'max': 12.0},
                'activation-time(h)': {'min': 0.0, 'max': 55.0},
                'hydrothermal-T(â„ƒ)': {'min': 180, 'max': 300},
                'hydrothermal-time(h)': {'min': 0.5, 'max': 6.0},
                'hydrothermal-SLR(g/ml)': {'min': 0.001, 'max': 0.2},
                'adsorption-SLR(g/L)': {'min': 0.0, 'max': 50.0},
                'adsorption-time(h)': {'min': 0.0, 'max': 24.0},
                'pH': {'min': 5.0, 'max': 9.0},
                'RPM(r/min)': {'min': 100.0, 'max': 300.0},
                'adsorption-T(â„ƒ)': {'min': 20.0, 'max': 50.0},
                'S(%)': {'min': 0.0, 'max': 3.0},
                'N(%)': {'min': 0.0, 'max': 28.0},
                'H(%)': {'min': 3.0, 'max': 10.0},
                'C(%)': {'min': 20.0, 'max': 80.0},
                'O(%)': {'min': 5.0, 'max': 60.0},
                'H/C': {'min': 0.0, 'max': 4.0}, 
                '(O+N)/C': {'min': 0.0, 'max': 4.0},
            }

            fixed_params = {}
            optimize_vars = []
            optimize_bounds = []
            
            # è§£æè¾“å…¥ï¼ŒåŒºåˆ†å›ºå®šå€¼å’Œéœ€è¦ä¼˜åŒ–çš„å˜é‡
            for k, v in inputs.items():
                if isinstance(v, dict):
                    if v.get('is_predict', False):
                        # å¦‚æœå‹¾é€‰äº†"Predict" (Check)ï¼Œåˆ™è¯¥å˜é‡éœ€è¦åæ¨
                        optimize_vars.append(k)
                        # ç¡®å®šä¼˜åŒ–è¾¹ç•Œ
                        if k in BASE_HARD_LIMITS:
                            lb, ub = BASE_HARD_LIMITS[k]['min'], BASE_HARD_LIMITS[k]['max']
                        else:
                            stat = self.stats.get(k, {'min':0, 'max':100})
                            lb, ub = stat['min'], stat['max']
                        optimize_bounds.append((lb, ub))
                        fixed_params[k] = (lb + ub) / 2 # åˆå§‹å€¼ç»™ä¸ªä¸­é—´å€¼
                    else:
                        # å¦åˆ™å›ºå®šä¸ºç”¨æˆ·è¾“å…¥çš„å€¼
                        fixed_params[k] = v['value']
                else:
                    fixed_params[k] = v

            target_ads = targets['ads']['value'] if targets['ads']['is_constraint'] else None
            target_rem = targets['rem']['value'] if targets['rem']['is_constraint'] else None

            # é€»è¾‘å¼ºæ ¡éªŒå‡½æ•° (ç¡®ä¿ç‰©ç†é€»è¾‘ï¼Œå¦‚æœªæ´»åŒ–åˆ™ç›¸å…³å‚æ•°å½’é›¶)
            def enforce_logic(params):
                k_method = 'activation-method'
                k_slr = 'activation-SLR(g/L)'
                k_conc = 'activator-concentration(mol/L)'
                k_time = 'activation-time(h)'

                method = str(params.get(k_method, '')).strip()
                slr = params.get(k_slr, 0.0)
                conc = params.get(k_conc, 0.0)
                time = params.get(k_time, 0.0)
                threshold = 0.001 

                is_method_zero = (method == '0' or 'åŸºå‡†' in method or method == '')
                is_any_num_zero = (slr < threshold) or (conc < threshold) or (time < threshold)

                if is_method_zero or is_any_num_zero:
                    params[k_slr] = 0.0
                    params[k_conc] = 0.0
                    params[k_time] = 0.0
                else:
                    min_phys = 0.1 
                    if params[k_slr] < min_phys: params[k_slr] = min_phys
                    if params[k_conc] < min_phys: params[k_conc] = min_phys
                    if params[k_time] < 1.0: params[k_time] = 1.0

                return params

            # æ™ºèƒ½æ ¡éªŒå‡½æ•° (Smart Verification)
            def calc_verification_metrics(params, ads, rem):
                # 1. è´¨é‡å®ˆæ’è¯¯å·®
                mb_err = 0.0
                mb_msg = "N/A"
                try:
                    c0 = params.get('initial-NH4+-N(mg/L)', 0)
                    slr = params.get('adsorption-SLR(g/L)', 0)
                    if c0 > 1.0 and slr > 0:
                        theo_rem = (ads * slr * 100) / c0
                        mb_err = abs(rem - theo_rem)
                        mb_msg = f"{mb_err:.2f}%"
                except: pass

                # 2. å…ƒç´ å¹³è¡¡ (æ™ºèƒ½åæ¨)
                elem_err = 0.0
                elem_msg = "N/A"
                try:
                    h = params.get('H(%)', 0)
                    n = params.get('N(%)', 0)
                    s = params.get('S(%)', 0)
                    c = params.get('C(%)', 0)
                    o = params.get('O(%)', 0)
                    
                    # è¡¥å…¨é€»è¾‘
                    if c <= 0.001:
                        hc_ratio = params.get('H/C', 0)
                        if hc_ratio > 0 and h > 0:
                            c = h / hc_ratio
                            params['C(%)'] = c 

                    if o <= 0.001:
                        onc_ratio = params.get('(O+N)/C', 0)
                        if onc_ratio > 0 and c > 0:
                            o = (onc_ratio * c) - n
                            if o < 0: o = 0 
                            params['O(%)'] = o 

                    total = c + h + o + n + s
                    if total > 5.0: 
                        elem_err = abs(total - 100.0)
                        elem_msg = f"{total:.2f}% (Err: {elem_err:.2f}%)"
                    else:
                        elem_msg = "Insufficient Data"
                except: pass
                
                return {
                    'mass_balance_error': mb_err,
                    'mass_balance_msg': mb_msg,
                    'elemental_error': elem_err,
                    'elemental_msg': elem_msg
                }

            # --- æ¨¡å¼ A: æ­£å‘é¢„æµ‹ (Predict Mode) ---
            # å¦‚æœæ²¡æœ‰å˜é‡è¢«å‹¾é€‰ä¸º"åæ¨"ï¼Œåˆ™ç›´æ¥è®¡ç®—
            if not optimize_vars:
                fixed_params = enforce_logic(fixed_params) 
                df = self._build_input_df(fixed_params)
                pred = self.model.predict(df)[0]
                verify = calc_verification_metrics(fixed_params, pred[0], pred[1])
                return {'success': True, 'mode': 'forward', 'ads': pred[0], 'rem': pred[1], 'verification': verify}

            # --- æ¨¡å¼ B: é€†å‘ä¼˜åŒ– (Reverse / Optimization Mode) ---
            
            # å®šä¹‰ç›®æ ‡å‡½æ•° (Loss Function)
            def objective(x):
                current = fixed_params.copy()
                # å°†ä¼˜åŒ–çš„å˜é‡å€¼å¡«å…¥å‚æ•°å­—å…¸
                for i, var in enumerate(optimize_vars):
                    current[var] = x[i]
                current = enforce_logic(current)
                
                # é¢„æµ‹å½“å‰å‚æ•°ä¸‹çš„ç»“æœ
                df = self._build_input_df(current)
                pred = self.model.predict(df)[0]
                p_ads, p_rem = pred[0], pred[1]
                
                loss = 0
                # è®¡ç®—ä¸ç›®æ ‡çš„å·®è·
                if target_ads: loss += abs(p_ads - target_ads) / (target_ads + 1e-6)
                if target_rem: loss += abs(p_rem - target_rem) / (target_rem + 1e-6)
                # å¦‚æœæ²¡æœ‰è®¾å®šç›®æ ‡å€¼ï¼Œåˆ™é»˜è®¤æœ€å¤§åŒ–å¸é™„é‡å’Œå»é™¤ç‡ (æœ€å°åŒ–è´Ÿå€¼)
                if not target_ads and not target_rem: loss = - (p_ads + p_rem) 
                
                # ç‰©ç†çº¦æŸæƒ©ç½š (Soft Constraints)
                metrics = calc_verification_metrics(current, p_ads, p_rem)
                if metrics['mass_balance_error'] > 5.0: loss += metrics['mass_balance_error'] * 0.1
                if metrics['elemental_error'] > 2.0: loss += metrics['elemental_error'] * 0.1

                return loss

            best_vals = []
            
            # ğŸ”¥ è°ƒç”¨è‡ªå®šä¹‰é—ä¼ ç®—æ³• ğŸ”¥
            try:
                best_vals = self._run_genetic_algorithm(
                    objective, 
                    optimize_bounds, 
                    pop_size=50,       # ç§ç¾¤å¤§å°
                    generations=40,    # è¿­ä»£æ¬¡æ•°
                    mutation_rate=0.1  # å˜å¼‚ç‡
                )
            except Exception as e:
                # å…œåº•ï¼šå¦‚æœGAè¿ç®—å‡ºé”™ï¼Œé€€åŒ–ä¸ºéšæœºæœç´¢
                print(f"Genetic Algorithm failed: {e}, using Random Search instead.")
                best_score = float('inf')
                for _ in range(500):
                    x_try = [random.uniform(b[0], b[1]) for b in optimize_bounds]
                    sc = objective(x_try)
                    if sc < best_score: best_score, best_vals = sc, x_try

            # æ•´ç†æœ€ç»ˆç»“æœ
            final_res_params = fixed_params.copy()
            for i, var in enumerate(optimize_vars):
                final_res_params[var] = best_vals[i]
            
            final_res_params = enforce_logic(final_res_params)
            
            final_df = self._build_input_df(final_res_params)
            final_pred = self.model.predict(final_df)[0]
            
            verify = calc_verification_metrics(final_res_params, final_pred[0], final_pred[1])
            
            # è¡¥å…¨å¯èƒ½è¢«åæ¨çš„å…³è”å…ƒç´  (å¦‚C/O)
            if 'C(%)' in final_res_params and 'C(%)' not in optimize_vars:
                 optimize_vars.append('C(%)')
            if 'O(%)' in final_res_params and 'O(%)' not in optimize_vars:
                 optimize_vars.append('O(%)')

            return {
                'success': True, 
                'mode': 'reverse',
                'ads': final_pred[0], 
                'rem': final_pred[1],
                'optimized_params': {k: final_res_params[k] for k in optimize_vars},
                'verification': verify
            }

        except Exception as e:
            return {'success': False, 'error': f"Logic Error: {str(e)}\n{traceback.format_exc()}"}
